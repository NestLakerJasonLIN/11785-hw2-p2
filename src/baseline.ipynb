{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "verbose = True\n",
    "mode = \"actual\"\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 4 if cuda else 0 \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    print(\"mode: %s\" % mode)\n",
    "    print(\"torch version: %s\" % torch.__version__)\n",
    "    print(\"np version: %s\" % np.__version__)\n",
    "    print(\"cuda: %s\" % cuda)\n",
    "    print(\"num_workers: %s\" % num_workers)\n",
    "    print(\"device: %s\" % device)\n",
    "    print(\"verbose: %s\" % verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/\"\n",
    "pred = \"../pred/\"\n",
    "\n",
    "pred_cls_filename = pred + \"test_cls_pred.csv\"\n",
    "pred_vrf_filename = pred + \"test_vrf_pred.csv\"\n",
    "dataset_cat = \"medium\"\n",
    "\n",
    "eval_cls = root + \"validation_classification/\" + dataset_cat\n",
    "test_cls = root + \"test_classification/\" + \"medium\"\n",
    "if (mode==\"development\"):\n",
    "    train_cls = eval_cls # for development\n",
    "else:\n",
    "    train_cls = root + \"train_data/\" + dataset_cat # for actual training\n",
    "\n",
    "eval_vrf = root + \"validation_verification\"\n",
    "test_vrf = root + \"test_verification\"\n",
    "\n",
    "test_cls_order_path = root + \"test_order_classification.txt\"\n",
    "test_vrf_order_path = root + \"test_trials_verification_student.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if (verbose):\n",
    "    print(\"loading dataset...\")\n",
    "\n",
    "class testClassfiyDataset(Dataset):\n",
    "    def __init__(self, test_path, transforms, test_cls_order_path):\n",
    "        super().__init__()\n",
    "\n",
    "        self.test_path = test_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # load image order file\n",
    "        self.image_order_list = np.loadtxt(test_cls_order_path, dtype=str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_order_list)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        image_rel_path = self.image_order_list[index]\n",
    "        image_path = self.test_path + \"/\" + image_rel_path\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root = train_cls, transform=transformations)\n",
    "eval_dataset = datasets.ImageFolder(root = eval_cls, transform=transformations)\n",
    "test_dataset = testClassfiyDataset(test_cls, transformations, test_cls_order_path)\n",
    "\n",
    "if (verbose):\n",
    "    print(\"load train dataset: \", len(train_dataset))\n",
    "    print(\"load eval dataset: \", len(eval_dataset))\n",
    "    print(\"load test dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "input_shape = torch.Size([3, 32, 32])\n",
    "num_faceids = len(train_dataset.classes)\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,              # The dataset\n",
    "    batch_size=batch_size,      # Batch size\n",
    "    shuffle=True,               # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,            # Copy data to CUDA pinned memory\n",
    "    num_workers=num_workers     # Number of worker processes for loading data.\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "\n",
    "        outputs = model(data)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         predicted.detach_()\n",
    "#         total_predictions += target.size(0)\n",
    "#         correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() \n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "#     acc = (correct_predictions / total_predictions) * 100.0\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "#     print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(eval_loader)):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(eval_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('evaluate Loss: ', running_loss)\n",
    "        print('evaluate Accuracy: ', acc, '%')\n",
    "        return running_loss, acc\n",
    "\n",
    "def test_model(model, test_loader, device, save=False, filename=\"../data/test_pred.csv\"):\n",
    "    predicts = torch.LongTensor().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # no target in test dataset/data loader\n",
    "        for batch_idx, data in enumerate(tqdm(test_loader)):\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            \n",
    "            predicts = torch.cat([predicts, predict])\n",
    "    \n",
    "    assert predicts.shape[0] == len(test_loader.dataset)\n",
    "    assert predicts.shape[0] == len(test_loader.dataset.image_order_list)\n",
    "    \n",
    "    if save:\n",
    "        # convert label index back to real indentity label\n",
    "        predict_labels = []\n",
    "        for i in predicts.detach().cpu().numpy():\n",
    "            predict_labels.append(\n",
    "                [key  for (key, value) in train_dataset.class_to_idx.items() if value == i][0])\n",
    "        \n",
    "        result = np.concatenate([test_loader.dataset.image_order_list.reshape(-1, 1),\n",
    "                                 np.asarray(predict_labels).reshape(-1, 1)], axis=1)\n",
    "        np.savetxt(filename, result, fmt=\"%s\", delimiter=\",\", header=\"Id,Category\", comments=\"\")\n",
    "    \n",
    "    return predicts\n",
    "\n",
    "def train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device, scheduler=None):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch: %d\" % (epoch))\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device=device)\n",
    "        eval_loss, eval_acc = evaluate_model(model, eval_loader, criterion, device=device)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(eval_loss)\n",
    "        \n",
    "        print('=' * 20)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dBNReLU6(nn.Module):\n",
    "    # per paper:  All spatial convolutions use 3 Ã— 3 kernels\n",
    "    def __init__(self, cin, cout, ks=3, sd=1, pd=-1, grp=1, relu=True):\n",
    "        super(Conv2dBNReLU6, self).__init__()\n",
    "        \n",
    "        if (pd<0):\n",
    "            # reference: http://cs231n.github.io/convolutional-networks/\n",
    "            pd = (ks - 1) // 2\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # convolution layer, TODO: bias=False?\n",
    "        layers.append(nn.Conv2d(cin, cout, ks, sd, pd, groups=grp, bias=False))\n",
    "        \n",
    "        # batch norm layer\n",
    "        layers.append(nn.BatchNorm2d(cout))\n",
    "        \n",
    "        # relu layer\n",
    "        if (relu):\n",
    "            # use inplace to improve memory usage\n",
    "            layers.append(nn.ReLU6(inplace=True))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, cin, t, cout, sd):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        \n",
    "        self.cin = cin\n",
    "        self.cout = cout\n",
    "        \n",
    "        if (cin == cout):\n",
    "            assert sd == 1\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # expanision : 1x1 conv2d , ReLU6\n",
    "        c_expan = cin * t\n",
    "        layers.append(Conv2dBNReLU6(cin, c_expan, ks=1, sd=1))\n",
    "        \n",
    "        # depth-wise convolution : 3x3 dwise s=s, ReLU6\n",
    "        layers.append(Conv2dBNReLU6(c_expan, c_expan, ks=3, sd=sd, grp=c_expan))\n",
    "        \n",
    "        # projection : linear 1x1 conv2d, no ReLU6\n",
    "        layers.append(Conv2dBNReLU6(c_expan, cout, ks=1, sd=1, pd=0, relu=False))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        # use residual if input/output has same shape\n",
    "        if (self.cin == self.cout):\n",
    "            out += x\n",
    "        return out\n",
    "        \n",
    "    \n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, in_shape, output_size, dropout=0.2):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        # all hyper-parameters\n",
    "        cin, w, h = in_shape[0], in_shape[1], in_shape[2]\n",
    "        cout = 32 # first layer's output channels\n",
    "        # TUNE: stride\n",
    "        # t, c, n, s\n",
    "        bottleneck_architects = [\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 1],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 1],\n",
    "            [6, 320, 1, 1]\n",
    "        ]\n",
    "        c_last = 4096 # TUNE: last channel from bottlenecks\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # 1. first conv2d layer : kernel_size = 3 stride = 1, cin, cout, ks, sd\n",
    "        layers.append(Conv2dBNReLU6(cin, cout, 3, 1))\n",
    "        cin = cout\n",
    "\n",
    "        # 2. 17 bottleneck blocks\n",
    "        for t, c, n, s in bottleneck_architects:\n",
    "            cout = c\n",
    "            for i in range(n):\n",
    "                # per paper: The first layer of each sequence has a stride s and all others use stride 1.\n",
    "                s = s if i == 0 else 1\n",
    "                # cin, t, cout, sd                \n",
    "                layers.append(BottleNeck(cin, t, cout, s))\n",
    "                cin = cout\n",
    "\n",
    "        # 3. last conv2d layer: cout=c_last, ks = 1 sd = 1\n",
    "        layers.append(Conv2dBNReLU6(cin, c_last, 1, 1))\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*layers); # separate for verification task\n",
    "        \n",
    "        # 4. avgpool layer avgpool convert to only 1 feature\n",
    "        # trick: use torch.mean to finish this in forward method later\n",
    "\n",
    "        # 5. classify layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            # TODO: do we need dropout here ? Per paper, yes.\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(c_last, output_size)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get embedding feature\n",
    "        x = self.feature_extractor(x)\n",
    "        \n",
    "        # avgpool layer\n",
    "        x = x.mean([2, 3])\n",
    "\n",
    "        # classify layer\n",
    "        x = self.classifier(x) \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(in_shape=input_shape,\n",
    "                    output_size=num_faceids, dropout=dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.to(device).parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "if verbose:\n",
    "    print(\"training...\")\n",
    "\n",
    "train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filename = \"checkpoint_6.tar\"\n",
    "checkpoint = {}\n",
    "checkpoint[\"model_state_dict\"] = model.state_dict()\n",
    "checkpoint[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "\n",
    "torch.save(checkpoint, checkpoint_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting\n",
    "if verbose:\n",
    "    print(\"predicting...\")\n",
    "\n",
    "predicts = test_model(model, test_loader, device, save=True, filename=pred_cls_filename)\n",
    "\n",
    "if verbose:\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: do not support development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testVerifyDataset(Dataset):\n",
    "    def __init__(self, test_path, transforms):\n",
    "        super().__init__()\n",
    "\n",
    "        self.test_path = test_path\n",
    "        self.image_paths = glob.glob(test_path + \"/*.jpg\")\n",
    "        self.transforms = transforms\n",
    "        self.image_lookup_table = build_lookup_table(self.image_paths, test_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        test_single_data = self.transforms(image)\n",
    "        \n",
    "        return test_single_data\n",
    "\n",
    "def build_lookup_table(image_paths, test_vrf_path):\n",
    "    image_lookup_table = {}\n",
    "    \n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        image_name = image_path.replace(test_vrf_path + \"/\", \"\")\n",
    "        image_idx = idx\n",
    "        image_lookup_table[image_name] = idx\n",
    "    \n",
    "    return image_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vrf_dataset = testVerifyDataset(test_vrf, transformations)\n",
    "\n",
    "test_vrf_loader = DataLoader(\n",
    "    test_vrf_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embs(model_vrf, test_vrf_loader, device):\n",
    "    embs = torch.FloatTensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_vrf.eval()\n",
    "\n",
    "        model_vrf.to(device)\n",
    "\n",
    "        for batch_idx, data in enumerate(tqdm(test_vrf_loader)):\n",
    "            data = data.to(device)\n",
    "            outputs = model_vrf(data)\n",
    "            embs = torch.cat([embs, outputs])\n",
    "\n",
    "    assert embs.shape[0] == len(test_vrf_loader.dataset)\n",
    "\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_similarity(test_vrf_order_path, image_lookup_table, save=False, filename=\"\"):\n",
    "    trial_order_list = np.loadtxt(test_vrf_order_path, dtype=str)\n",
    "\n",
    "    similarity_scores = torch.tensor([]).reshape(-1, 1).to(device)\n",
    "\n",
    "    for i, j in tqdm(trial_order_list):\n",
    "        iidx, jidx = image_lookup_table[i], image_lookup_table[j]\n",
    "        iemb, jemb = embs[iidx], embs[jidx]\n",
    "        similarity_score = get_similarity(iemb, jemb)\n",
    "\n",
    "        similarity_scores = torch.cat((similarity_scores, similarity_score.reshape(-1, 1)))\n",
    "        \n",
    "    result = np.concatenate([trial_order_list, similarity_scores.cpu().numpy()], \n",
    "                            axis=1)\n",
    "    \n",
    "    np.savetxt(filename, result, fmt=\"%s %s,%s\", header=\"trial,score\", comments=\"\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    return torch.dot(a, b) / (torch.norm(a) * torch.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut linear layer to get verficiation model\n",
    "# TODO: detach\n",
    "if verbose:\n",
    "    print(\"generating face embedding...\")\n",
    "model_vrf = nn.Sequential(*(list(model.net.children())[:-7]))\n",
    "embs = generate_embs(model_vrf, test_vrf_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict similarity\n",
    "# TODO: a little bit slow, try to speed up! currently ~2min\n",
    "if verbose:\n",
    "    print(\"predicting verfication...\")\n",
    "result = predict_similarity(test_vrf_order_path, \n",
    "                   test_vrf_dataset.image_lookup_table,\n",
    "                   save=True, filename=pred_vrf_filename)\n",
    "\n",
    "if verbose:\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, output_size, device):\n",
    "        super(CNN, self).__init__()\n",
    "        self.net = nn.Sequential()\n",
    "        shape = (input_shape[1], input_shape[2])\n",
    "        \n",
    "        # in_c, out_c, ks, sd, pd\n",
    "        shape = self._add_conv2d(shape, 3, 64, 5, 1, 2)\n",
    "        # ks, sd, pd\n",
    "        shape = self._add_maxpool(shape, 3, 2, 1)\n",
    "        shape = self._add_conv2d(shape, 64, 192, 5, 1, 2)\n",
    "        shape = self._add_maxpool(shape, 3, 2, 1)\n",
    "        shape = self._add_conv2d(shape, 192, 384, 3, 1, 1)\n",
    "        shape = self._add_conv2d(shape, 384, 256, 3, 1, 1)\n",
    "        shape = self._add_conv2d(shape, 256, 256, 3, 1, 1)\n",
    "        \n",
    "        shape = self._add_maxpool(shape, 3, 2, 1)\n",
    "\n",
    "        self._add_module(nn.Flatten())\n",
    "        \n",
    "        linear_input_size = shape[0] * shape[1] * 256\n",
    "\n",
    "        self._add_module(nn.Linear(linear_input_size, 4096))\n",
    "        self._add_module(nn.BatchNorm1d(num_features=4096))\n",
    "        self._add_module(nn.ReLU())\n",
    "        self._add_module(nn.Linear(4096, 4096))\n",
    "        self._add_module(nn.BatchNorm1d(num_features=4096))\n",
    "        self._add_module(nn.ReLU())\n",
    "        self._add_module(nn.Linear(4096, output_size))\n",
    "\n",
    "    def _add_conv2d(self, in_shape, in_c, out_c, ks, sd, pd):\n",
    "        self._add_module(nn.Conv2d(in_channels=in_c, \n",
    "                                   out_channels=out_c, \n",
    "                                   kernel_size=ks, \n",
    "                                   stride=sd, \n",
    "                                   padding=pd))\n",
    "        \n",
    "        out_shape = self._get_output_size(in_shape, ks, sd, pd)\n",
    "        self._add_module(nn.BatchNorm2d(num_features=out_c))\n",
    "        self._add_module(nn.ReLU())\n",
    "        return out_shape\n",
    "    \n",
    "    def _add_maxpool(self, in_shape, ks, sd, pd):\n",
    "        self._add_module(nn.MaxPool2d(kernel_size=ks, \n",
    "                                       stride=sd, \n",
    "                                       padding=pd))\n",
    "        \n",
    "        out_shape = self._get_output_size(in_shape, ks, sd, pd)\n",
    "        return out_shape\n",
    "        \n",
    "    # assume dilation is always 1\n",
    "    def _get_output_size(self, in_shape, ks, sd, pd):\n",
    "        dilation = 1\n",
    "        h_in, w_in = in_shape\n",
    "        h_out = (int)((h_in + 2 * pd - dilation * (ks - 1) - 1) / sd + 1)\n",
    "        w_out = (int)((h_in + 2 * pd - dilation * (ks - 1) - 1) / sd + 1)\n",
    "        return (h_out, w_out)\n",
    "    \n",
    "    def _add_module(self, module):\n",
    "        self.net.add_module(str(len(self.net)), module)\n",
    "    \n",
    "    def _get_linear_input_size(self, input_shape, device):\n",
    "        fake_input = torch.zeros((1, *input_shape)).to(device)\n",
    "        self.net.to(device)\n",
    "        fake_output = self.net(fake_input)\n",
    "        assert len(fake_output.shape) == 2 # must be after flatten\n",
    "        linear_input_size = fake_output.shape[1]\n",
    "        return linear_input_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
