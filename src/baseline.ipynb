{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "verbose = True\n",
    "mode = \"actual\"\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 4 if cuda else 0 \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    print(\"mode: %s\" % mode)\n",
    "    print(\"torch version: %s\" % torch.__version__)\n",
    "    print(\"np version: %s\" % np.__version__)\n",
    "    print(\"cuda: %s\" % cuda)\n",
    "    print(\"num_workers: %s\" % num_workers)\n",
    "    print(\"device: %s\" % device)\n",
    "    print(\"verbose: %s\" % verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/\"\n",
    "\n",
    "pred_filename = \"test_pred.csv\"\n",
    "dataset_cat = \"medium\"\n",
    "\n",
    "eval_cls = root + \"validation_classification/\" + dataset_cat\n",
    "test_cls = root + \"test_classification/\" + \"medium\"\n",
    "if (mode==\"development\"):\n",
    "    train_cls = eval_cls # for development\n",
    "else:\n",
    "    train_cls = root + \"train_data/\" + dataset_cat # for actual training\n",
    "\n",
    "eval_vrf = root + \"validation_verification\"\n",
    "test_vrf = root + \"test_verification\"\n",
    "\n",
    "test_cls_order_path = root + \"test_order_classification.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if (verbose):\n",
    "    print(\"loading dataset...\")\n",
    "\n",
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_path, transform, test_cls_order_path):\n",
    "        super().__init__()\n",
    "\n",
    "        self.test_path = test_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # load image order file\n",
    "        self.image_order_list = np.loadtxt(test_cls_order_path, dtype=str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_order_list)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        image_rel_path = self.image_order_list[index]\n",
    "        image_path = self.test_path + \"/\" + image_rel_path\n",
    "        image = Image.open(image_path)\n",
    "        test_single_data = self.transform(image)\n",
    "        \n",
    "        return test_single_data\n",
    "\n",
    "# TODO: may need to normalize images\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root = train_cls, transform=transformations)\n",
    "eval_dataset = datasets.ImageFolder(root = eval_cls, transform=transformations)\n",
    "test_dataset = testDataset(test_cls, transforms.ToTensor(), test_cls_order_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "input_shape = torch.Size([3, 32, 32])\n",
    "num_faceids = len(train_dataset.classes)\n",
    "\n",
    "lr = 1e-3 # default lr is 1e-3\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "embedding_dim = 128 # How to use this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,              # The dataset\n",
    "    batch_size=batch_size,      # Batch size\n",
    "    shuffle=True,               # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,            # Copy data to CUDA pinned memory\n",
    "    num_workers=num_workers     # Number of worker processes for loading data.\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "\n",
    "        outputs = model(data)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted.detach_()\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    acc = (correct_predictions / total_predictions) * 100.0\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(eval_loader)):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(eval_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('evaluate Loss: ', running_loss)\n",
    "        print('evaluate Accuracy: ', acc, '%')\n",
    "        return running_loss, acc\n",
    "\n",
    "def test_model(model, test_loader, device, save=False, filename=\"../data/test_pred.csv\"):\n",
    "    predicts = torch.LongTensor().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # no target in test dataset/data loader\n",
    "        for batch_idx, data in enumerate(tqdm(test_loader)):\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predict = torch.max(outputs.data, 1)\n",
    "            \n",
    "            predicts = torch.cat([predicts, predict])\n",
    "    \n",
    "    assert predicts.shape[0] == len(test_loader.dataset)\n",
    "    assert predicts.shape[0] == len(test_loader.dataset.image_order_list)\n",
    "    \n",
    "    predict_labels = []\n",
    "    \n",
    "    # convert label index back to real indentity label\n",
    "    for i in predicts.detach().cpu().numpy():\n",
    "        predict_labels.append(\n",
    "            [key  for (key, value) in train_dataset.class_to_idx.items() if value == i][0])\n",
    "    \n",
    "    if save:\n",
    "        result = np.concatenate([test_loader.dataset.image_order_list.reshape(-1, 1),\n",
    "                                 np.asarray(predict_labels).reshape(-1, 1)], axis=1)\n",
    "        np.savetxt(filename, result, fmt=\"%s\", delimiter=\",\", header=\"Id,Category\", comments=\"\")\n",
    "    \n",
    "    return predicts\n",
    "\n",
    "def train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        print(\"epoch: %d\" % (epoch))\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device=device)\n",
    "        eval_loss, eval_acc = evaluate_model(model, eval_loader, criterion, device=device)\n",
    "        \n",
    "        print('=' * 20)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# TODO: add batchnorm\n",
    "# TODO: how to define embedding from conv2d ?\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, output_size, embedding_dim, device):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=56, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(in_channels=56, out_channels=28, kernel_size=6, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=28, out_channels=14, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # trick: infer linear input size\n",
    "        linear_input_size = self._get_linear_input_size(input_shape, device)\n",
    "        linear_module_key = str(len(self.net))\n",
    "        \n",
    "        self.net.add_module(linear_module_key, nn.Linear(linear_input_size, output_size))\n",
    "\n",
    "    def _get_linear_input_size(self, input_shape, device):\n",
    "        fake_input = torch.zeros((1, *input_shape)).to(device)\n",
    "        self.net.to(device)\n",
    "        fake_output = self.net(fake_input)\n",
    "        assert len(fake_output.shape) == 2 # must be after flatten\n",
    "        linear_input_size = fake_output.shape[1]\n",
    "        return linear_input_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_shape=input_shape,\n",
    "            output_size=num_faceids,\n",
    "            embedding_dim=embedding_dim,\n",
    "            device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.to(device).parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "if verbose:\n",
    "    print(\"training...\")\n",
    "\n",
    "train_model(model, epochs, train_loader, eval_loader,criterion,optimizer,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting\n",
    "if verbose:\n",
    "    print(\"predicting...\")\n",
    "\n",
    "predicts = test_model(model, test_loader, device, save=True, filename=pred_filename)\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
